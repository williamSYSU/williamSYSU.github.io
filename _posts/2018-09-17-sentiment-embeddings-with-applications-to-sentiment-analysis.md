---
layout:         post
title:          "Note - Sentiment embeddings with applications to sentiment analysis"
subtitle:       "如何把情感信息编码到词向量中，并提升情感分析的效果？"
data:           2018-09-17
author:         "William"
header-img:     "img/post-bg-sentiment-analysis.jpg"
tags:
    - NLP
    - Paper Notes
    - Sentiment Analysis
---



## Catalog

1. [Before Reading](#before-reading)
2. [Paper core](#paper-core)
3. [Model](#model)
   1. [Context Model](#上下文模型)
   2. [Sentiment Model](#情感模型)
   3. [Hybrid Model](#混合上下文和情感的模型)
4. [Key points of training](#key-points-of-training)
5. [Something can learn](#something-can-learn)
6. [Reference](#reference)



## Before Reading

1. 如何结合情感？

   > 通过两个模型的加权loss，返回去优化词的embedding，让词同时具有上下文信息和情感信息。

2. 结合情感后的词如何用来训练，用的是什么模型？

   > 带情感的词向量最后用来检验这些词向量是否具有一定的提升效果。在验证句子级别的情感问题时，用到了别人论文的两个数据集（SemEval和Rotten Tomatoes）。

3. 训练带情感的词向量和最终用于预测句子情感的数据集是否一样？

   > 不一样，首先用自己爬取的训练数据训练带情感的词向量，然后用其它数据集来验证词向量的效果。

4. 在训练目标词情感模型里，上下文词的词向量是否固定？

   > 论文未提及。
   >
   > **个人观点**：上下文的词向量固定，只训练目标词的词向量。句子前三个和后三个词无法作为目标词。

5. 训练目标词情感模型的label来自哪里？是不是目标词的情感label？

   > 这个label是指一个窗口大小中的情感倾向，而不是单指目标词的情感倾向，文中默认窗口的情感倾向与整个句子的情感倾向一致，因为twitter的数据比较短，窗口大小设为7时，其情感倾向与句子基本保持一致，所以窗口训练label用的是句子的情感倾向label

6. 是否具有词的情感语料库？

   > 有的，由一开始的少量情感基准词，假设它的同义词也与它具有相同的情感倾向，则将该基准词的情感倾向设为它的拓展词的情感倾向。

7. 文中仅收集带有情感符号的句子进行训练，能否确保其它不带情感符号的句子具有正确的情感倾向？

   > 可以，因为情感符号只是一个弱标签，一个句子的句法和语义不会因为一个情感符号而变化。

8. 单个词的情感倾向和句子或者窗口的情感倾向有什么联系？

   > 在结合上下文和情感两个词向量训练模型时，需要加入一个正则项，这个正则项规定了，在情感词库中，具有相同情感倾向的词，他们的词向量空间相距较近，不同的则相距较远，这就保证了在训练词向量时，能够以这个标准来进行。
   >
   > **正则项**：在训练过程中，用于约束某一个指标的表达式。表示在训练过程中，不但要减小总的损失，而且在减小的过程中，要满足正则项的要求。

9. 目标词和拓展词有什么联系？

   > 文中未提及。
   >
   > **个人观点**：在训练的过程中，目标词即拓展后的带情感的词库中的词，只训练在词库中的词。

10. 窗口在移动时，是否只把情感词典库里面的词作为目标词用来训练，跳过那些不在情感词库里面的词？



## Paper Core

论文通过结合两个基本模型（上下文模型和情感模型），使训练得到的词向量同时具有上下文信息和情感信息，最后验证带情感的词向量是否能够提升情感分析的效果。



## Model

通过两个分别的传统前向传播模型。

- 一个是对上下文词进行建模。即由一个词的所有上下文词的词向量（**不包括**目标词的词向量）经过两个全连接层最后输出一个大小为词典大小的Softmax结果。
- 另一个是对目标词的情感进行建模。由目标词和其所有上下文词的词向量，经过两个全连接层，最后经过Softmax输出一个2维的向量， 表示情感倾向。



### 上下文模型

流程：

1. 选取目标词的上下文词，拼接后作为输入；
2. 然后经过：$linear \to hTanh \to linear \to softmax$
3. 最后输出一个$1 \times V$的向量，其中$V$代表词典的大小



### 情感模型

流程：

1. 选取目标词以及其上下文词，拼接后作为输入；
2. 然后经过：$linear \to hTanh \to linear \to softmax$
3. 最后输出一个$1\times2$的向量，其中2代表情感的倾向数，论文中只讨论$positive$和$negative$
4. 在扫描整个句子时，是用一个固定大小的窗口在一个变长的句子上滑动，然后根据句子的情感倾向来预测每个窗口中的情感倾向。



### 混合上下文和情感的模型

为了使词向量同时具有上下文信息和情感信息，将上述的两个模型合并训练。

> **合并方式**：将两个模型的$loss$加权求和，然后优化总的$loss$。

在优化总的$loss$时，就把上下文信息和情感信息编码到词向量中。在上下文模型和情感模型中的第二个$linear$层，它们的权值*共享*，其上一个$linear$层的输出维数保持一致。

> **加入正则化**：在结合上下文和情感两个词向量训练模型时，需要加入一个正则项，这个正则项规定了，在情感词库中，具有相同情感倾向的词，他们的词向量空间相距较近，不同的则相距较远，这就保证了在训练词向量时，能够以这个标准来进行。

加入正则化后，就让拓展的词与目标词联系在一起，将拓展词的情感倾向来控制目标词的词向量训练过程。



## Key points of training

1. 训练情感词向量的数据

   > 从Twitter上只爬取带有情感符号的句子，这样句子的情感倾向就能确定了。

   > 虽然直接这样确定句子的情感倾向不太正确，但是这仅用作弱监督的学习，这就足够了（仅用来学习词向量）。

2. 词级别的情感数据

   > **Word Cluster假设**：用Urban Dictionary的数据来确定与一个词相似词集合，这些相似词都具有相同的情感倾向。

   > 事先确定一组种子词，然后通过调用Urban Dictionary，确定词库中其它词的情感倾向。



## Something can learn

1. 论文提到了如何把情感信息编码到词向量中。

   > 论文中提到的方法是*同时优化上下文模型和情感模型的加权$loss$*，这样就可以使词向量同时包含上下文信息和情感信息。

2. 在训练词向量时，把句子级别的情感倾向和词级别的情感倾向联系到一起。

   > 论文中固定一个句子的情感倾向，然后用一个固定大小的窗口在句子上滑动，窗口的情感倾向于句子的情感倾向相同。在每训练一个目标词的情感词向量时，加入了正则化项，使词库中具有相同情感倾向的词的词向量在一个较近的空间内，这就把词级别的情感倾向联系上了。

3. 在验证自己的理论时，用到了多个方面的验证。

   > -如何验证训练好的情感词向量符合预期?
   >  -依据：一个词在词向量空间中也应该被具有相同情感倾向的词所包围。
   >  -方法：验证一个词离它最近的10个词，它们的情感倾向是否与它本身相同，计算相同的比率。
   > -如何验证情感词向量确实能提高情感分析效果？
   >  -方法：将训练好的情感词向量用于其它已有的benchmark，验证其效果是否比随机初始化或者其它初始化方法要好。

4. 训练带情感词向量的本质思想。

   > 本论文通过大量的数据集来训练一个带情感信息的词向量，这有点类似于弱监督训练的前半个过程，在Weakly-supervised deep embedding for product review sentiment analysis这篇论文中，也是用弱监督训练得到一个较好的句子表示。该论文训练得到的是一个词级别的特征向量，而那一篇论文训练得到的是一个句子级别的特征向量。``



## Reference

*D. Tang, F. Wei, B. Qin, N. Yang, T. Liu, and M. Zhou, “Sentiment Embeddings with Applications to Sentiment Analysis,” IEEE Trans. Knowl. Data Eng., vol. 28, no. 2, pp. 496–509, 2016.*